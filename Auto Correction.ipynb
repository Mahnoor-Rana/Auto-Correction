{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c5944f1",
   "metadata": {},
   "source": [
    "## Installing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc1fff2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting patternNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading Pattern-3.6.0.tar.gz (22.2 MB)\n",
      "Requirement already satisfied: future in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pattern) (0.18.2)\n",
      "Collecting backports.csv\n",
      "  Downloading backports.csv-1.0.7-py2.py3-none-any.whl (12 kB)\n",
      "Collecting mysqlclient\n",
      "  Downloading mysqlclient-2.1.1-cp39-cp39-win_amd64.whl (178 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pattern) (4.11.1)\n",
      "Requirement already satisfied: lxml in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pattern) (4.8.0)\n",
      "Requirement already satisfied: feedparser in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pattern) (6.0.10)\n",
      "Collecting pdfminer.six\n",
      "  Downloading pdfminer.six-20220524-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pattern) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pattern) (1.7.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pattern) (3.7)\n",
      "Collecting python-docx\n",
      "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
      "Collecting cherrypy\n",
      "  Downloading CherryPy-18.8.0-py2.py3-none-any.whl (348 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pattern) (2.27.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from beautifulsoup4->pattern) (2.3.1)\n",
      "Collecting cheroot>=8.2.1\n",
      "  Downloading cheroot-8.6.0-py2.py3-none-any.whl (104 kB)\n",
      "Collecting portend>=2.1.1\n",
      "  Downloading portend-3.1.0-py3-none-any.whl (5.3 kB)\n",
      "Collecting more-itertools\n",
      "  Downloading more_itertools-8.14.0-py3-none-any.whl (52 kB)\n"
     ]
    }
   ],
   "source": [
    "pip install pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5195a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autocorrect\n",
      "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
      "Building wheels for collected packages: autocorrect\n",
      "  Building wheel for autocorrect (setup.py): started\n",
      "  Building wheel for autocorrect (setup.py): finished with status 'done'\n",
      "  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622382 sha256=6c63a54fe8c0e469768c5b6d27a09db420846b9c691a064033ef37472575d713\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\ab\\0f\\23\\3c010c3fd877b962146e7765f9e9b08026cac8b035094c5750\n",
      "Successfully built autocorrect\n",
      "Installing collected packages: autocorrect\n",
      "Successfully installed autocorrect-2.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install autocorrect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c947ff99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspellchecker in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.6.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspellchecker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5d319c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.64.0)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2022.3.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.4)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88a574e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textdistance in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textdistance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b3d92e",
   "metadata": {},
   "source": [
    "## Reading Text file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "911babe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preprocessing \n",
    "import re \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f5352f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a Corpus\n",
    "words = []\n",
    "with open(\"Text.txt\",'r',encoding=\"utf8\") as f:\n",
    "    file_data = f.read()\n",
    "    file_data = file_data.lower()\n",
    "    words = re.findall('\\w+',file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f2e9fcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of dictionary 1001\n",
      "First 5 words  of dictionary are \n",
      "['a', 'ability', 'able', 'about', 'above', 'accept', 'according', 'account', 'across', 'act']\n"
     ]
    }
   ],
   "source": [
    "v = set(words)\n",
    "print(f'len of dictionary {len(v)}')\n",
    "print(f'First 5 words  of dictionary are \\n{words[0:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8d4c26bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1001 key values pairs\n"
     ]
    }
   ],
   "source": [
    "## Frequency and Probability\n",
    "def get_count(words):\n",
    "    word_count_dict = {}\n",
    "    for word in words:\n",
    "        if word in word_count_dict:\n",
    "            word_count_dict[word] += 1\n",
    "        else:\n",
    "            word_count_dict[word] = 1\n",
    "    return word_count_dict\n",
    "word_count_dict = get_count(words)\n",
    "print(f\"There are {len(word_count_dict)} key values pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1dbbe14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probability that any word will appear if randomly selected from the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a57e4572",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_probs(word_count_dict):\n",
    "    probs = {}\n",
    "    m = sum(word_count_dict.values())\n",
    "    for key in word_count_dict.keys():\n",
    "        probs[key] = word_count_dict[key] / m\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7be165f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove a letter from a given word\n",
    "def del_letter(word):\n",
    "    del_list= []\n",
    "    split_list = []\n",
    "    for i in range(len(word)):\n",
    "        split_list.append((word[0:i],word[i:]))\n",
    "    for a , b in split_list:\n",
    "        del_list.append(a+b[1:])\n",
    "    return del_list\n",
    "\n",
    "del_letter_1= del_letter(word = \"hush\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "72572827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ush', 'hsh', 'huh', 'hus']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del_letter_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3249cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## switch a letter from a given word\n",
    "def switch_letter(word):\n",
    "    switch_list= []\n",
    "    split_list = []\n",
    "    for i in range(len(word)):\n",
    "        split_list.append((word[0:i],word[i:]))\n",
    "    split_list = [a +b[1] + b[0] + b[2:] for a , b in split_list if len(b) >=2]\n",
    "    return split_list\n",
    "\n",
    "switch_letter_1= switch_letter(word = \"hush\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cd3d8c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uhsh', 'hsuh', 'huhs']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "switch_letter_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "645d6722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace letter (change one letter with other)\n",
    "def replace_lett(word):\n",
    "    replace_list= []\n",
    "    split_list = []\n",
    "    for i in range(len(word)):\n",
    "        split_list.append((word[0:i],word[i:]))\n",
    "    alphabets = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    replace_list =  [a +l + (b[1:] if len(b) >1 else \" \") for a, b in split_list if b  for l in alphabets]\n",
    "    return replace_list\n",
    "\n",
    "replace_letter_1= replace_lett(word = \"hush\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "234a4efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aush',\n",
       " 'bush',\n",
       " 'cush',\n",
       " 'dush',\n",
       " 'eush',\n",
       " 'fush',\n",
       " 'gush',\n",
       " 'hush',\n",
       " 'iush',\n",
       " 'jush',\n",
       " 'kush',\n",
       " 'lush',\n",
       " 'mush',\n",
       " 'nush',\n",
       " 'oush',\n",
       " 'push',\n",
       " 'qush',\n",
       " 'rush',\n",
       " 'sush',\n",
       " 'tush',\n",
       " 'uush',\n",
       " 'vush',\n",
       " 'wush',\n",
       " 'xush',\n",
       " 'yush',\n",
       " 'zush',\n",
       " 'hash',\n",
       " 'hbsh',\n",
       " 'hcsh',\n",
       " 'hdsh',\n",
       " 'hesh',\n",
       " 'hfsh',\n",
       " 'hgsh',\n",
       " 'hhsh',\n",
       " 'hish',\n",
       " 'hjsh',\n",
       " 'hksh',\n",
       " 'hlsh',\n",
       " 'hmsh',\n",
       " 'hnsh',\n",
       " 'hosh',\n",
       " 'hpsh',\n",
       " 'hqsh',\n",
       " 'hrsh',\n",
       " 'hssh',\n",
       " 'htsh',\n",
       " 'hush',\n",
       " 'hvsh',\n",
       " 'hwsh',\n",
       " 'hxsh',\n",
       " 'hysh',\n",
       " 'hzsh',\n",
       " 'huah',\n",
       " 'hubh',\n",
       " 'huch',\n",
       " 'hudh',\n",
       " 'hueh',\n",
       " 'hufh',\n",
       " 'hugh',\n",
       " 'huhh',\n",
       " 'huih',\n",
       " 'hujh',\n",
       " 'hukh',\n",
       " 'hulh',\n",
       " 'humh',\n",
       " 'hunh',\n",
       " 'huoh',\n",
       " 'huph',\n",
       " 'huqh',\n",
       " 'hurh',\n",
       " 'hush',\n",
       " 'huth',\n",
       " 'huuh',\n",
       " 'huvh',\n",
       " 'huwh',\n",
       " 'huxh',\n",
       " 'huyh',\n",
       " 'huzh',\n",
       " 'husa ',\n",
       " 'husb ',\n",
       " 'husc ',\n",
       " 'husd ',\n",
       " 'huse ',\n",
       " 'husf ',\n",
       " 'husg ',\n",
       " 'hush ',\n",
       " 'husi ',\n",
       " 'husj ',\n",
       " 'husk ',\n",
       " 'husl ',\n",
       " 'husm ',\n",
       " 'husn ',\n",
       " 'huso ',\n",
       " 'husp ',\n",
       " 'husq ',\n",
       " 'husr ',\n",
       " 'huss ',\n",
       " 'hust ',\n",
       " 'husu ',\n",
       " 'husv ',\n",
       " 'husw ',\n",
       " 'husx ',\n",
       " 'husy ',\n",
       " 'husz ']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_letter_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "45243acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace letter (change one letter with other)\n",
    "def Insert_lett(word):\n",
    "    insert_list= []\n",
    "    split_list = []\n",
    "    for i in range(len(word)+ 1):\n",
    "        split_list.append((word[0:i],word[i:]))\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    replace_list =  [a +l + b for a, b in split_list   for l in letters]\n",
    "    return replace_list\n",
    "\n",
    "insert_letter_1= Insert_lett(word = \"hush\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4f4b12f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ahush',\n",
       " 'bhush',\n",
       " 'chush',\n",
       " 'dhush',\n",
       " 'ehush',\n",
       " 'fhush',\n",
       " 'ghush',\n",
       " 'hhush',\n",
       " 'ihush',\n",
       " 'jhush',\n",
       " 'khush',\n",
       " 'lhush',\n",
       " 'mhush',\n",
       " 'nhush',\n",
       " 'ohush',\n",
       " 'phush',\n",
       " 'qhush',\n",
       " 'rhush',\n",
       " 'shush',\n",
       " 'thush',\n",
       " 'uhush',\n",
       " 'vhush',\n",
       " 'whush',\n",
       " 'xhush',\n",
       " 'yhush',\n",
       " 'zhush',\n",
       " 'haush',\n",
       " 'hbush',\n",
       " 'hcush',\n",
       " 'hdush',\n",
       " 'heush',\n",
       " 'hfush',\n",
       " 'hgush',\n",
       " 'hhush',\n",
       " 'hiush',\n",
       " 'hjush',\n",
       " 'hkush',\n",
       " 'hlush',\n",
       " 'hmush',\n",
       " 'hnush',\n",
       " 'housh',\n",
       " 'hpush',\n",
       " 'hqush',\n",
       " 'hrush',\n",
       " 'hsush',\n",
       " 'htush',\n",
       " 'huush',\n",
       " 'hvush',\n",
       " 'hwush',\n",
       " 'hxush',\n",
       " 'hyush',\n",
       " 'hzush',\n",
       " 'huash',\n",
       " 'hubsh',\n",
       " 'hucsh',\n",
       " 'hudsh',\n",
       " 'huesh',\n",
       " 'hufsh',\n",
       " 'hugsh',\n",
       " 'huhsh',\n",
       " 'huish',\n",
       " 'hujsh',\n",
       " 'huksh',\n",
       " 'hulsh',\n",
       " 'humsh',\n",
       " 'hunsh',\n",
       " 'huosh',\n",
       " 'hupsh',\n",
       " 'huqsh',\n",
       " 'hursh',\n",
       " 'hussh',\n",
       " 'hutsh',\n",
       " 'huush',\n",
       " 'huvsh',\n",
       " 'huwsh',\n",
       " 'huxsh',\n",
       " 'huysh',\n",
       " 'huzsh',\n",
       " 'husah',\n",
       " 'husbh',\n",
       " 'husch',\n",
       " 'husdh',\n",
       " 'huseh',\n",
       " 'husfh',\n",
       " 'husgh',\n",
       " 'hushh',\n",
       " 'husih',\n",
       " 'husjh',\n",
       " 'huskh',\n",
       " 'huslh',\n",
       " 'husmh',\n",
       " 'husnh',\n",
       " 'husoh',\n",
       " 'husph',\n",
       " 'husqh',\n",
       " 'husrh',\n",
       " 'hussh',\n",
       " 'husth',\n",
       " 'husuh',\n",
       " 'husvh',\n",
       " 'huswh',\n",
       " 'husxh',\n",
       " 'husyh',\n",
       " 'huszh',\n",
       " 'husha',\n",
       " 'hushb',\n",
       " 'hushc',\n",
       " 'hushd',\n",
       " 'hushe',\n",
       " 'hushf',\n",
       " 'hushg',\n",
       " 'hushh',\n",
       " 'hushi',\n",
       " 'hushj',\n",
       " 'hushk',\n",
       " 'hushl',\n",
       " 'hushm',\n",
       " 'hushn',\n",
       " 'husho',\n",
       " 'hushp',\n",
       " 'hushq',\n",
       " 'hushr',\n",
       " 'hushs',\n",
       " 'husht',\n",
       " 'hushu',\n",
       " 'hushv',\n",
       " 'hushw',\n",
       " 'hushx',\n",
       " 'hushy',\n",
       " 'hushz']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_letter_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "03ac2d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining edits\n",
    "def edit_one_letter(word, allow_switches = True):\n",
    "    edit_set1 = set()\n",
    "    edit_set1.update(del_letter(word))\n",
    "    if allow_switches :\n",
    "        edit_set1.update(switch_letter(word))\n",
    "    edit_set1.update(replace_lett(word))\n",
    "    edit_set1.update(Insert_lett(word))\n",
    "    return edit_set1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "50861e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_two_letter(word, allow_switches = True ):\n",
    "    edit_set2 = set()\n",
    "    edit_one = edit_one_letter(word, allow_switches=allow_switches)\n",
    "    for w in edit_one:\n",
    "        if w :\n",
    "            edit_two = edit_one_letter(w, word, allow_switches)\n",
    "            edit_set2.update(edit_two)\n",
    "    return edit_set2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "482b3ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corrections(word, prob,vocab , n=2):\n",
    "    suggest_word = []\n",
    "    best_sugg = []\n",
    "    \n",
    "    suggested_word = list(\n",
    "        (word in vocab and word) or edit_one_letter(word).intersection(vocab) or edit_two_letters(word).intersection(\n",
    "            vocab))\n",
    "    best_suggestion = [[s, probs[s]] for s in list(reversed(suggested_word))]\n",
    "    return best_suggestion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a76ae54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter word : gae\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'age'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [166]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m input_word \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnter word : \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m probs \u001b[38;5;241m=\u001b[39m get_probs(get_count(input_word))\n\u001b[1;32m----> 3\u001b[0m correc \u001b[38;5;241m=\u001b[39m \u001b[43mget_corrections\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_word\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i , word_prob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(correc):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword_prob[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, probability\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword_prob[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [165]\u001b[0m, in \u001b[0;36mget_corrections\u001b[1;34m(word, prob, vocab, n)\u001b[0m\n\u001b[0;32m      3\u001b[0m best_sugg \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m suggested_word \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m      6\u001b[0m     (word \u001b[38;5;129;01min\u001b[39;00m vocab \u001b[38;5;129;01mand\u001b[39;00m word) \u001b[38;5;129;01mor\u001b[39;00m edit_one_letter(word)\u001b[38;5;241m.\u001b[39mintersection(vocab) \u001b[38;5;129;01mor\u001b[39;00m edit_two_letters(word)\u001b[38;5;241m.\u001b[39mintersection(\n\u001b[0;32m      7\u001b[0m         vocab))\n\u001b[1;32m----> 8\u001b[0m best_suggestion \u001b[38;5;241m=\u001b[39m [[s, probs[s]] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(suggested_word))]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_suggestion\n",
      "Input \u001b[1;32mIn [165]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m best_sugg \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m suggested_word \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m      6\u001b[0m     (word \u001b[38;5;129;01min\u001b[39;00m vocab \u001b[38;5;129;01mand\u001b[39;00m word) \u001b[38;5;129;01mor\u001b[39;00m edit_one_letter(word)\u001b[38;5;241m.\u001b[39mintersection(vocab) \u001b[38;5;129;01mor\u001b[39;00m edit_two_letters(word)\u001b[38;5;241m.\u001b[39mintersection(\n\u001b[0;32m      7\u001b[0m         vocab))\n\u001b[1;32m----> 8\u001b[0m best_suggestion \u001b[38;5;241m=\u001b[39m [[s, \u001b[43mprobs\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(suggested_word))]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_suggestion\n",
      "\u001b[1;31mKeyError\u001b[0m: 'age'"
     ]
    }
   ],
   "source": [
    "input_word = input('Enter word : ')\n",
    "probs = get_probs(get_count(input_word))\n",
    "correc = get_corrections(input_word, probs, v, 2)\n",
    "for i , word_prob in enumerate(correc):\n",
    "    print(f'word{i}: {word_prob[0]}, probability{word_prob[1]:.6f}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
